{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# oneAPI及SYCL简介 | Introduction to oneAPI and SYCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 章节 | Sections\n",
    "- [oneAPI 编程模型概述] | [oneAPI Programming Model Overview](#oneAPI-Software-Model-Overview)\n",
    "- [多架构的编程挑战] | [Programming Challenges for Multiple architectures](#Programming-Challenges-for-Multiple-architectures)\n",
    "- [oneAPI 简介] | [Introducing oneAPI](#Introducing-oneAPI)\n",
    "- _代码 Code:_ [SYCL Hello World] | [SYCL Hello World](#Simple-Exercise)\n",
    "- [什么是SYCL] | [What is SYCL](#SYCL)\n",
    "- [如何编译和运行一个SYCL程序] | [How to Compile & Run a SYCL program](#How-to-Compile-&-Run-SYCL-program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 学习目标 | Learning Objectives\n",
    "\n",
    "* 说明 __oneAPI__ 编程模型如何应对异构环境中的编程挑战 | Explain how the __oneAPI__ programming model can solve the challenges of programming in a heterogeneous world \n",
    "* 使用 oneAPI 项目支持您的工作流程 | Use oneAPI projects to enable your workflows\n",
    "* 了解 __SYCL__ 语言和编程模型 | Understand the __SYCL__ language and programming model\n",
    "* 熟悉如何在整个课程中使用 Jupyter Notebook 进行培训 | Familiarization on the use Jupyter notebooks for training throughout the course\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"oneAPI-Software-Model-Overview\"></a>\n",
    "## oneAPI 编程模型概述 | oneAPI Programming Model Overview\n",
    "\n",
    "__oneAPI__ 编程模型提供了一个全面、统一的开发人员工具组合，可用于各种硬件设备，其中包括跨多个工作负载领域的一系列性能库。这些库包括面向各目标架构而定制化代码的函数，因此相同的函数调用可为各种支持的架构提供优化的性能。__SYCL__ 基于行业标准和开放规范，旨在鼓励生态系统的协作和创新。\n",
    "\n",
    "The __oneAPI__ programming model provides a comprehensive and unified portfolio of developer tools that can\n",
    "be used across hardware targets, including a range of performance libraries spanning several workload\n",
    "domains. The libraries include functions custom-coded for each target architecture so the same\n",
    "function call delivers optimized performance across supported architectures. __SYCL__ is based on\n",
    "industry standards and open specifications to encourage ecosystem collaboration and innovation.\n",
    "\n",
    "### oneAPI 分发 | oneAPI Distribution\n",
    "英特尔&reg; oneAPI 工具套件通过多个分发渠道提供：\n",
    "Intel&reg; oneAPI toolkits are available via multiple distribution channels:\n",
    "* 产品安装在本机：从 __英特尔® 开发人员专区__ 安装 oneAPI 工具套件。\n",
    "* Local product installation: install the oneAPI toolkits from the __Intel® Developer Zone__.\n",
    "* 从容器或存储库安装：从支持的任一容器或存储库安装 OneAPI 工具套件。\n",
    "* Install from containers or repositories: install the oneAPI toolkits from one of several supported\n",
    "containers or repositories.\n",
    "* 预装在__英特尔® DevCloud__ 中：使用免费的开发沙盒访问最新英特尔® SVMS (Scalar, Vector, Matrix, Spatial)硬件和部分oneAPI工具套件。\n",
    "* Pre-installed in the __Intel® DevCloud__: a free development sandbox for access to the latest Intel® SVMS hardware and select oneAPI toolkits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"Programming-Challenges-for-Multiple-architectures\"></a>\n",
    "\n",
    "## 多架构的编程挑战 | Programming Challenges for Multiple architectures\n",
    "\n",
    "在以数据为中心的空间中，专用工作负载的数量正在不断增长。每种以数据为中心的硬件通常都因为没有通用的编程语言或API而需要使用不同的语言和库进行编程，这就需要维护各自独立的代码库。由于跨平台的工具支持不一致，因此开发人员必须学习和使用一整套不同的工具。为每个硬件平台开发软件都需要单独的投资，并且几乎无法在开发另一个架构时重用之前的工作。您还必须考虑以数据为中心的各种广泛的硬件需求。\n",
    "\n",
    "Currently in the data centric space there is growth in specialized workloads. Each kind of data centric hardware typically needs to be programmed using different languages and libraries as there is no common programming language or APIs, this requires maintaining separate code bases. Developers have to learn a whole set of different tools as there is inconsistent tool support across platforms. Developing software for each hardware platform requires a separate investment, with little ability to reuse that work to target a different architecture. You will also have to consider the requirement of the diverse set of data-centric hardware.\n",
    "\n",
    "<img src=\"Assets/oneapi1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Introducing-oneAPI\"></a>\n",
    "## oneAPI 简介 | Introducing oneAPI\n",
    "\n",
    "__oneAPI__ 是一种利用统一编程模型__简化各种架构开发__的解决方案。它包括统一简化的语言以及用于表达__并行性__的库， 并能够为包括 __CPU、 GPU 和 FPGA__ 等一系列硬件提供出色的原生高级语言性能。oneAPI 计划基于 __行业标准和开放规范__ ，并且可以与现有的 HPC 编程模型互操作。\n",
    "\n",
    "__oneAPI__ is a solution to deliver unified programming model to __simplify development__ across diverse architectures. It includes a unified and simplified language and libraries for expressing __parallelism__ and delivers uncompromised native high-level language performance across a range of hardware including __CPUs, GPUs, FPGAs__. oneAPI initiative is based on __industry standards and open specifications__ and is interoperable with existing HPC programming models.\n",
    "\n",
    "<img src=\"Assets/oneapi2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"Simple-Exercise\"> </a>\n",
    "***\n",
    "# 简单练习 | Simple Exercise\n",
    "\n",
    "本练习通过简单的小段代码为开发人员展示SYCL。此外，它还向开发人员展示了 Jupyter Notebook 环境，该环境可用于编辑和保存代码；以及运行程序并将程序提交至英特尔® DevCloud。\n",
    "\n",
    "This exercise introduces SYCL to the developer by way of a small simple code. In addition, it introduces the developer to the Jupyter notebook environment for editing and saving code; and for running and submitting programs to the Intel® DevCloud.\n",
    "\n",
    "##  编辑 simple.cpp 代码 | Editing the simple.cpp code\n",
    "下方带灰色背景的 Jupyter 单元可以进行原地编辑和保存。\n",
    "\n",
    "The Jupyter cell below with the gray background can be edited in-place and saved.\n",
    "\n",
    "单元的第一行包含 **%%writefile 'simple.cpp'** 命令。此命令会告知输入单元将其内容保存到当前目录（通常是你的home主目录）中名为‘simple.cpp’的文件中。当您编辑该单元并在 Jupyter Notebook 中运行时，您所做的更改将保存到该文件中。\n",
    "\n",
    "The first line of the cell contains the command **%%writefile 'simple.cpp'** This tells the input cell to save the contents of the cell into a file named 'simple.cpp' in your current directory (usually your home directory). As you edit the cell and run it in the Jupyter notebook, it will save your changes into that file.\n",
    "\n",
    "下面的代码是一些简单的 SYCL 代码，可帮助您快速了解 DevCloud 环境。只需检查代码，无需修改。运行第一个单元以创建文件，然后运行其下方的单元，以编译并执行代码。\n",
    "\n",
    "The code below is some simple SYCL code to get you started in the DevCloud environment. Simply inspect the code - there are no modifications necessary. Run the first cell to create the file, then run the cell below it to compile and execute the code.\n",
    "\n",
    "1. 检查下面的代码单元，然后点击运行 ▶，将代码保存到文件中\n",
    "\n",
    "Inspect the code cell below, then click run ▶ to save the code to a file\n",
    "\n",
    "2. 在代码片段下面的__构建并运行__部分中运行 ▶单元，以编译并执行保存文件中的代码\n",
    "\n",
    "Run ▶ the cell in the __Build and Run__ section below the code snippet to compile and execute the code in the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile lab/simple.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "using namespace sycl;\n",
    "static const int N = 16;\n",
    "int main(){\n",
    "  //# define queue which has default device associated for offload\n",
    "  queue q;\n",
    "  std::cout << \"Device: \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# Unified Shared Memory Allocation enables data access on host and device\n",
    "  int *data = malloc_shared<int>(N, q);\n",
    "\n",
    "  //# Initialization\n",
    "  for(int i=0; i<N; i++) data[i] = i;\n",
    "\n",
    "  //# Offload parallel computation to device\n",
    "  q.parallel_for(range<1>(N), [=] (id<1> i){\n",
    "    data[i] *= 2;\n",
    "  }).wait();\n",
    "\n",
    "  //# Print Output\n",
    "  for(int i=0; i<N; i++) std::cout << data[i] << \"\\n\";\n",
    "\n",
    "  free(data, q);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建并运行 | Build and Run\n",
    "选择下面的单元，然后点击运行 ▶，编译并执行上面的代码：\n",
    "\n",
    "Select the cell below and click Run ▶ to compile and execute the code above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_simple.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_simple.sh; else ./run_simple.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SYCL\"></a>\n",
    "## SYCL | SYCL\n",
    "\n",
    "__SYCL__（读作‘sickle’）代表了一项行业标准化工作，其中包括对 C++ 数据并行编程的支持。它被总结为“用于OpenCL的C++ 单源异构编程”。SYCL标准和OpenCL一样是由 __Khronos Group*__ 管理。\n",
    "\n",
    "__SYCL__ (pronounced ‘sickle’) represents an industry standardization effort that includes\n",
    "support for data-parallel programming for C++. It is summarized as “C++ Single-source\n",
    "Heterogeneous Programming for OpenCL.” The SYCL standard, like OpenCL*, is managed\n",
    "by the __Khronos Group*__.\n",
    "\n",
    "SYCL是建立在OpenCL之上的跨平台抽象层。它支持使用C++以“单源”样式编写用于异构处理器的代码。这不仅对程序员有用，而且还使编译器能够在整个程序中进行分析和优化，而与运行代码的设备无关。\n",
    "\n",
    "SYCL is a cross-platform abstraction layer that builds on OpenCL. It enables code\n",
    "for heterogeneous processors to be written in a “single source” style using C++. This is not\n",
    "only useful to the programmers, but it also gives a compiler the ability to analyze and\n",
    "optimize across the entire program regardless of the device on which the code is to be run.\n",
    "\n",
    "与OpenCL不同，SYCL包括模板和lambda函数，支持高级应用软件通过优化的内核代码加速快速编码。\n",
    "开发人员在OpenCL之上的更高层级进行编程，但始终可以通过与OpenCL及C/C++库的无缝集成来访问底层代码。\n",
    "\n",
    "Unlike OpenCL, SYCL includes templates and lambda functions to enable higher-level application software to be cleanly coded with optimized acceleration of kernel code.\n",
    "Developers program at a higher level than OpenCL but always have access to lower-level code through seamless integration with OpenCL, as well as C/C++ libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是数据并行 C++ | What is Data Parallel C++\n",
    "\n",
    "__Data Parallel C++ (DPC++)__ 是oneAPI基于SYCL的编译器实现。它具有现代 C++ 的效率优势和众所周知的构造，并结合了用于数据并行性和异构编程的 __SYCL*__ 标准。SYCL 是一个 __单源__ 语言，可将 __主机代码__ 和 __异构加速器内核__ 混编在同一个源文件中。在主机上调用 DPC++ 程序，并将计算卸载到加速器。程序员可以使用熟悉的 C++ 和库构造及多项新增功能（如用于工作定向的 __队列(queue)__ 、用于数据管理的 __缓冲区(buffer)__ 和用于并行性的 __parallel_for__ ）来管理可以分流卸载的部分计算和数据。\n",
    "\n",
    "\n",
    "__Data Parallel C++ (DPC++)__ is oneAPI's implementation of SYCL compiler. It takes advantage of modern C++ productivity benefits and familiar constructs, and incorporates the __SYCL*__ standard for data parallelism and heterogeneous programming. SYCL is a __single source__ language where __host code__ and __heterogeneous accelerator kernels__ can be mixed in same source files. A SYCL program is invoked on the host computer and offloads the computation to an accelerator. Programmers use familiar C++ and library constructs with added functionalities like a __queue__ for work targeting, __buffer__ for data management, and __parallel_for__ for parallelism to direct which parts of the computation and data should be offloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DPC++ 扩展了 SYCL | DPC++ extends SYCL\n",
    "DPC++ 程序 __可提高工作效率__。简单的事情应更易于表达，而且应有助于减少冗长与程序员的负担。它们还可以帮助程序员控制程序的执行并支持特定硬件功能，进而 __提高性能__。它是一种采用快速演进的开放式协作模式，且对接 __SYCL* 标准__，同时它也是一种 __开源__ 实现，旨在将 LLVM 和 DPC++ 扩展作为上游(upstream)，成为核心 __SYCL*__ 或 __Khronos*__ 扩展。\n",
    "\n",
    "DPC++ programs __enhance productivity__. Simple things should be simple to express and lower verbosity and programmer burden. They also __enhance performance__ by giving programmers control over program execution and by enabling hardware-specific features. It is a fast-moving open collaboration feeding into the __SYCL* standard__, and is an __open source__ implementation with the goal of upstreaming LLVM and DPC++ extensions to become core __SYCL*__, or __Khronos*__ extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 采用oneAPI的HPC单节点工作流程 | HPC Single Node Workflow with oneAPI \n",
    "\n",
    "加速代码可以使用核心函数(SYCL)或 __基于指令式的编程风格__。开发人员可以使用 __英特尔® DPC++ 兼容工具__ 来执行从 __CUDA__ 到 __SYCL__ 的一次性代码迁移。现有的 __Fortran__ 应用可以使用 __基于 OpenMP 的指令式编程风格__。现有的 __C++__ 应用可以选择使用 __基于核心函数式编程风格__ 或 __基于指令式的编程风格__ 选项，而现有的 __OpenCL__ 应用可以继续使用 OpenCL 语言或迁移到SYCL。\n",
    "\n",
    "Accelerated code can be written in either a kernel (SYCL) or __directive-based style__. Developers can use the __Intel® DPC++ Compatibility tool__ to perform a one-time migration from __CUDA__ to __SYCL__. Existing __Fortran__ applications can use a __directive-based style in OpenMP__. Existing __C++__ applications can choose either the __Kernel style__ or the __directive-based style__ option and existing __OpenCL__ applications can remain in the OpenCL language or migrate to SYCL.\n",
    "\n",
    "建议使用 __英特尔® Advisor__ 对 __矢量化和内存__ （CPU 和 GPU）的设计进行 __优化__ ，并 __寻找__ 可 __卸载分流__ 的循环并预测 __在目标加速器上的性能__ 。\n",
    "\n",
    "__Intel® Advisor__ is recommended to  __Optimize__ the design for __vectorization and memory__ (CPU and GPU) and __Identify__ loops that are candidates for __offload__ and project the __performance on target accelerators.__\n",
    "\n",
    "下图显示了针对 HPC 开发人员的不同起点的推荐方法：\n",
    "\n",
    "The figure below shows the recommended approach of different starting points for HPC developers:\n",
    "\n",
    "\n",
    "<img src=\"Assets/workflow.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oneAPI 编程模型 | oneAPI Programming models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平台模型 | Platform Model\n",
    "\n",
    "oneAPI的平台模型基于SYCL* 的平台模型。它指定控制一个或多个设备的主机(host)。主机是计算机，通常是基于CPU的系统，执行程序的主要部分，特别是应用范围(application scope)和命令组范围(command group scope)。  \n",
    "\n",
    "The platform model for oneAPI is based upon the SYCL* platform model. It specifies a host controlling one or more devices. A host is the computer, typically a CPU-based system executing the primary portion of a program, specifically the application scope and the command group scope. \n",
    "\n",
    "主机协调并控制在设备上执行的计算工作。设备(device)是加速器，是包含计算资源的专门组件，可以快速执行操作的子集，通常比系统中的CPU效率更高。每个设备包含一个或多个计算单元，可以并行执行多个操作。每个计算单元包含一个或多个处理元素(procsesing elements)，充当单独的计算引擎。\n",
    "\n",
    "The host coordinates and controls the compute work that is performed on the devices. A device is an accelerator, a specialized component containing compute resources that can quickly execute a subset of operations typically more efficiently than the CPUs in the system. Each device contains one or more compute units that can execute several operations in parallel. Each compute unit contains one or more processing elements that serve as the individual engine for computation.\n",
    "\n",
    "下图所示为平台模型中关于关系的可视化描述。一个主机与一个或多个设备通信。每个设备可以包含一个或多个计算单元。每个计算单元可以包含一个或多个处理元素。在本示例中，桌面计算机中的CPU是主机，它也可以作为平台配置中的设备。\n",
    "\n",
    "The following figure provides a visual depiction of the relationships in the platform model. One host communicates with one or more devices. Each device can contain one or more compute units. Each compute unit can contain one or more processing elements. In this example, the CPU in a desktop computer is the host and it can also be made available as a device in a platform configuration.\n",
    "\n",
    "<img src=\"Assets/plat30.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 执行模型 | Execution Model\n",
    "\n",
    "执行模型基于 SYCL* 执行模型。它定义并指定代码（称为内核kernel）如何在设备上执行并与控制主机交互。\n",
    "主机执行模型通过命令组(command group)协调主机和设备之间的执行和数据管理。命令组（由内核调用、访问器accessor等命令组成）被提交到执行队列。\n",
    "\n",
    "The execution model is based upon the SYCL* execution model. It defines and specifies how code, termed kernels, execute on the devices and interact with the controlling host.\n",
    "The host execution model coordinates execution and data management between the host and devices via command groups. The command groups, which are groupings of commands like kernel invocation and accessors, are submitted to queues for execution.\n",
    "\n",
    "访问器(accessor)形式上是内存模型的一部分，它还传达执行的顺序要求。使用执行模型的程序声明并实例化队列。可以使用程序可控制的有序或无序策略执行队列。有序执行是一项英特尔扩展。\n",
    "\n",
    "Accessors, which are formally part of the memory model, also communicate ordering requirements of execution. A program employing the execution model declares and instantiates queues. Queues can execute with an in-order or out-of-order policy controllable by the program. In-order execution is an Intel extension.\n",
    "\n",
    "设备执行模型指定如何在加速器上完成计算。对于从小型一维数据到大型多维数据集的计算在ND-range、工作组(work-group)、子组(sub-group)（英特尔扩展）和工作项(work-item)的层次结构中进行分配，这些都在工作提交到命令队列(command queue)时进行指定。\n",
    "\n",
    "The device execution model specifies how computation is accomplished on the accelerator. Compute ranging from small one-dimensional data to large multidimensional data sets are allocated across a hierarchy of ND-ranges, work-groups, sub-groups (Intel extension), and work-items, which are all specified when the work is submitted to the command queue.\n",
    "\n",
    "需注意的是，实际内核代码表示为一个工作项执行的工作。内核外的代码用来控制执行的并行度大小；工作的数量和分配由 ND-range和工作组的规范所控制。\n",
    "\n",
    "It is important to note that the actual kernel code represents the work that is executed for one work-item. The code outside of the kernel controls just how much parallelism is executed; the amount and distribution of the work is controlled by specification of the sizes of the ND-range and work-group.\n",
    "\n",
    "下图描述了 ND-range、工作组、子组和工作项之间的关系。总工作量由ND-range的大小指定。工作的分组由工作组大小指定。本例显示了ND-range的大小 X * Y * Z，工作组的大小 X’ * Y’ * Z’，以及子组的大小 X’。因此，有 X * Y * Z 工作项。有 (X * Y * Z) / (X’ * Y’ * Z’) 工作组和 (X * Y * Z) / X’ 子组。\n",
    "\n",
    "The following figure depicts the relationship between an ND-range, work-group, sub-group, and work-item. The total amount of work is specified by the ND-range size. The grouping of the work is specified by the work-group size. The example shows the ND-range size of X * Y * Z, work-group size of X’ * Y’ * Z’, and subgroup size of X’. Therefore, there are X * Y * Z work-items. There are (X * Y * Z) / (X’ * Y’ * Z’) work-groups and (X * Y * Z) / X’ subgroups.\n",
    "\n",
    "<img src=\"Assets/kernel30.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 内存模型 | Memory Model\n",
    "\n",
    "oneAPI 的内存模型基于 SYCL* 内存模型。它定义主机和设备如何与内存交互。它协调主机和设备之间内存的分配和管理。内存模型是一种抽象，旨在泛化和适应各种不同的主机和设备的配置。\n",
    "\n",
    "The memory model for oneAPI is based upon the SYCL* memory model. It defines how the host and devices interact with memory. It coordinates the allocation and management of memory between the host and devices. The memory model is an abstraction that aims to generalize across and be adaptable to the different possible host and device configurations.\n",
    "\n",
    "在此模型中，内存驻留在主机或设备上，并由其所有，通过声明内存对象来指定。内存对象有两种：缓冲器和图像。这些内存对象通过访问器在主机和设备之间进行交互，访问器传达期望的访问位置（如主机或设备）和特定的访问模式（如读或写）。\n",
    "\n",
    "In this model, memory resides upon and is owned by either the host or the device and is specified by declaring a memory object. There are two different types of memory objects, buffers and images. Interaction of these memory objects between the host and device is accomplished via an accessor, which communicates the desired location of access, such as host or device, and the particular mode of access, such as read or write.\n",
    "\n",
    "考虑这样一个案例：通过传统的 malloc 调用在主机上分配内存。主机上分配内存后，会创建一个缓冲区对象，支持主机分配的内存与设备通信。缓冲类将该类型及其待通信的类型的项传达给用于计算的设备。在主机上创建缓冲器后，设备支持的访问类型将通过访问器对象通信，指定访问缓冲器的类型。\n",
    "\n",
    "Consider a case where memory is allocated on the host through a traditional malloc call. Once the memory is allocated on the host, a buffer object is created, which enables the host allocated memory to be communicated to the device. The buffer class communicates the type and number of items of that type to be communicated to the device for computation. Once a buffer is created on the host, the type of access allowed on the device is communicated via an accessor object, which specifies the type of access to the buffer.\n",
    "\n",
    "<img src=\"Assets/memory.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 内核编程模型 | Kernel Programming Model\n",
    "\n",
    "面向 oneAPI 的内核编程模式基于 SYCL* 内核编程模型。它支持主机和设备之间的显式并行性。并行性是显式的，因为是由程序员决定在主机和设备上执行什么代码；它不是自动的。内核代码在加速器上执行。\n",
    "\n",
    "The kernel programming model for oneAPI is based upon the SYCL* kernel programming model. It enables explicit parallelism between the host and device. The parallelism is explicit in the sense that the programmer determines what code executes on the host and device; it is not automatic. The kernel code executes on the accelerator. \n",
    "\n",
    "采用 oneAPI 编程模型的程序支持单源，这意味着主机代码和设备代码可以在同一个源文件中。但主机代码中所接受的源代码与设备代码在语言一致性和语言特性方面存在差异。\n",
    "\n",
    "Programs employing the oneAPI programming model support single source, meaning the host code and device code can be in the same source file. However, there are differences between the source code accepted in the host code and the device code with respect to language conformance and language features. \n",
    "\n",
    "SYCL 规范详细定义了主机代码和设备代码所需的语言特性。以下是与 oneAPI 产品有关的一些总结。 \n",
    "\n",
    "The SYCL Specification defines in detail the required language features for host code and device code. The following is a summary that is specific to the oneAPI product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"How-to-Compile-&-Run-SYCL-program\"></a>\n",
    "\n",
    "How-to-Compile-&-Run-SYCL-program\n",
    "## 如何编译和运行 SYCL 程序 | How to Compile & Run SYCL program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "编译和运行 DPC++ 程序的三个主要步骤是： | The three main steps of compiling and running a SYCL program are:\n",
    "1. 初始化环境变量 | Initialize environment variables\n",
    "2. 编译 DPC++ 源代码 | Compile the SYCL source code\n",
    "3. 运行应用 | Run the application\n",
    " \n",
    "#### 在英特尔&reg; DevCloud 上编译并运行： | Compiling and Running on Intel&reg; DevCloud:\n",
    " \n",
    "在本次培训中，我们编写了一个脚本 (q) 来帮助开发人员在 DevCloud 上开发项目。该脚本将`run.sh`脚本提交到 DevCloud 上的 gpu 节点进行执行，等待作业完成并打印输出/错误。我们将使用此命令在 DevCloud 运行：`./q run.sh`\n",
    "\n",
    "For this training, we have written a script (q) to aid developers in developing projects on DevCloud. This script submits the `run.sh` script to a GPU node on DevCloud for execution, waits for the job to complete and prints out the output/errors. We will be using this command to run on DevCloud: `./q run.sh`\n",
    "\n",
    "\n",
    "#### 在本地系统上编译并运行： | Compiling and Running on a Local System:\n",
    "\n",
    "如果您在本地系统上安装了英特尔&reg; 基础工具套件，则可以使用以下命令来编译和运行 SYCL 程序：\n",
    "\n",
    "If you have installed the Intel&reg; oneAPI Base Toolkit on your local system, you can use the commands below to compile and run a SYCL program:\n",
    "\n",
    "    source /opt/intel/inteloneapi/setvars.sh\n",
    "\n",
    "    icpx -fsycl simple.cpp -o simple\n",
    "\n",
    "    ./simple\n",
    "\n",
    " __注：run.sh 脚本是上述三个命令的组合。__\n",
    "\n",
    "__Note: run.sh script is a combination of the three steps listed above.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结 | Summary\n",
    "在本模块中，您已学到以下内容：\n",
    "* oneAPI 如何应对异构环境中的编程挑战 \n",
    "* 利用 oneAPI 解决方案支持你的工作流程\n",
    "* 使用英特尔® DevCloud 测试 oneAPI 工具和库\n",
    "* SYCL 语言和编程模型的基础知识\n",
    "* 熟悉 Juypter Notebook 的用法，在上下文中编辑源代码。\n",
    "\n",
    "In this module you will have learned the following:\n",
    "* How oneAPI solves the challenges of programming in a heterogeneous world \n",
    "* Take advantage of oneAPI solutions to enable your workflows\n",
    "* Use the Intel® DevCloud to test-drive oneAPI tools and libraries\n",
    "* Basics of the SYCL language and programming model\n",
    "* Become familiarized with the use of Juypter notebooks by editing of source code in context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><body><span style=\"color:green\"><h1>调查 | Survey</h1></span></body></html>\n",
    "\n",
    "[参加一个简短的调查，为我们提供有关本模块的反馈意见。我们将使用您的反馈意见来提高这些学习材料的质量和影响力。谢谢！](https://intel.az1.qualtrics.com/jfe/form/SV_6m4G7BXPNSS7FBz)\n",
    "\n",
    "[Tell us how we did in this module with a short survey. We will use your feedback to improve the quality and impact of these learning materials. Thanks!](https://intel.az1.qualtrics.com/jfe/form/SV_6m4G7BXPNSS7FBz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 资源 | Resources\n",
    "\n",
    "查看这些相关资源 | Check out these related resources\n",
    "\n",
    "#### 英特尔® oneAPI 工具套件文档 | Intel® oneAPI Toolkit documentation\n",
    "* [oneAPI 主页 | Intel® oneAPI main page](https://software.intel.com/oneapi \"oneAPI main page\")\n",
    "* [英特尔® oneAPI 编程指南 | Intel® oneAPI programming guide](https://www.intel.com/content/www/us/en/docs/oneapi/programming-guide/2023-0/overview.html \"oneAPI programming guide\")\n",
    "* [英特尔® DevCloud 注册 | Intel® DevCloud Signup](https://www.intel.com/content/www/cn/zh/secure/forms/devcloud/enrollment.html \"Intel DevCloud\")  如果您没有帐户，请点击此处注册。 | Sign up here if you do not have an account.\n",
    "* [英特尔® DevCloud Connect | Intel® DevCloud Connect](https://jupyter.oneapi.devcloud.intel.com/hub/login?next=/lab/tree/Welcome.ipynb?reset \"Intel DevCloud Login\")   在此登录到 DevCloud。 | Login to the DevCloud here.\n",
    "* [oneAPI for Linux 入门* | Get Started with oneAPI for Linux*](https://software.intel.com/en-us/get-started-with-intel-oneapi-linux)\n",
    "* [oneAPI for Windows 入门* | Get Started with oneAPI for Windows*](https://software.intel.com/en-us/get-started-with-intel-oneapi-windows)\n",
    "* [英特尔® oneAPI 代码示例 | Intel® oneAPI Code Samples](https://www.intel.com/content/www/us/en/develop/documentation/explore-dpcpp-samples-from-intel/top.html)\n",
    "* [oneAPI 规范组成元素 | oneAPI Specification elements](https://www.oneapi.com/spec/)\n",
    "\n",
    "#### SYCL | SYCL \n",
    "* [SYCL 2020 规范 | SYCL 2020 Specification](https://www.khronos.org/registry/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf)\n",
    "\n",
    "#### 现代C++ | Modern C++\n",
    "* [C++参考 | CPPReference](https://en.cppreference.com/w/)\n",
    "* [CPlusPlus网站 | CPlusPlus](http://www.cplusplus.com/)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "525.6px",
    "left": "28px",
    "top": "137.8px",
    "width": "301.109px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
